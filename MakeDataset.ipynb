{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "These last decades, Earth Observation brought quantities of new perspectives from geosciences to human activity monitoring. As more data became available, artificial intelligence techniques led to very successful results for understanding remote sensing data. Moreover, various acquisition techniques such as Synthetic Aperture Radar (SAR) can also be used for problems that could not be tackled only through optical images. This is the case for weather-related disasters such as floods or hurricanes, which are generally associated with large clouds cover. Yet, machine learning on SAR data is still considered challenging due to the lack of available labeled data. This dataset is composed of co-registered optical and SAR images time series for the detection of flood events.\n",
    "\n",
    "Downloaded from Radiant ML Hub : https://mlhub.earth/data/sen12floods\n",
    "\n",
    "Citation\n",
    "ClÃ©ment Rambour, Nicolas Audebert, Elise Koeniguer, Bertrand Le Saux, Michel Crucianu, Mihai Datcu, September 14, 2020, \"SEN12-FLOOD : a SAR and Multispectral Dataset for Flood Detection \", IEEE Dataport, doi: https://dx.doi.org/10.21227/w6xz-s898.\n",
    "\n",
    "# Dataset\n",
    "\n",
    "The dataset is composed of 412 time series with 4 to 20 optical images and 10 to 58 SAR im- ages in each sequence. On average, there are 9 optical and 14 SAR images per sequence. The period of acquisition goes from December 2018 to May 2019. A flood event is occuring in 40% of the optical Sentinel 2 images and in 47% of the SAR Sen- tinel 1 images. As in the MediaEval dataset, once a flood oc- curred in a sequence, all the subsequent images are labeled as flooded which corresponds to the hypothesis that the surface still presents characteristic modifications after the event."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import All libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import gc\n",
    "import rasterio as rio\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import  cm\n",
    "import cv2\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CFG:\n",
    "    \"\"\"\n",
    "    This class provides a set of parameters and constants that may be used throughout a machine learning \n",
    "    pipeline for image classification, specifically in the context of identifying flooded areas.\n",
    "    \"\"\"\n",
    "    seed = 7 # random initialization of weights in a machine learning model\n",
    "    img_size = (256,256) # representing the dimensions of an image, specifically 256 x 256 pixels.\n",
    "    BATCH_SIZE = 3 #  representing the number of samples that will be fed to a machine learning model during training.\n",
    "    Autotune = tf.data.AUTOTUNE # a constant value from the tf.data.AUTOTUNE module that enables dynamic \n",
    "    # allocation of computational resources to improve performance.\n",
    "    validation_size = 0.2 # a float value of 0.2 representing the fraction of the training dataset to be used for validation during training.\n",
    "    class_dict= {0:'No Flooding', \n",
    "                 1: 'Flooding'}\n",
    "    \n",
    "    test_run = False # in training mode"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Data\n",
    "\n",
    "Read more about the dataset here : https://clmrmb.github.io/SEN12-FLOOD/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3332, 2237)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quick visual confirmation that all label files have corresponding source files in the dataset\n",
    "\n",
    "# Set the path for Dataset\n",
    "s1_labels = 'sen12flood/sen12floods_s1_labels/sen12floods_s1_labels/'\n",
    "s1_tiles = 'sen12flood/sen12floods_s1_source/sen12floods_s1_source/'\n",
    "\n",
    "s2_tiles = 'sen12flood/sen12floods_s2_source/sen12floods_s2_source/'\n",
    "s2_labels = 'sen12flood/sen12floods_s2_labels/sen12floods_s2_labels/'\n",
    "\n",
    "\n",
    "s1_check = 0\n",
    "for file in os.listdir(s1_labels):\n",
    "    if os.path.exists(s1_tiles + '/' + file.replace('labels','source')):\n",
    "        s1_check += 1\n",
    "        \n",
    "         \n",
    "assert s1_check == len(os.listdir(s1_tiles)), 'Not present'\n",
    "    \n",
    "s2_check = 0\n",
    "for file in os.listdir(s2_labels):\n",
    "    if os.path.exists(s2_tiles + '/' + file.replace('labels','source')):\n",
    "        s2_check += 1\n",
    "        \n",
    "        \n",
    "assert s2_check == len(os.listdir(s2_tiles)), 'Not present'\n",
    "\n",
    "\n",
    "s1_check,s2_check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(path):\n",
    "    '''loads a json file'''\n",
    "    with open(path,'r') as file:\n",
    "        js = json.load(file)\n",
    "        \n",
    "    return js\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_label_json(label_json):\n",
    "    '''process a single label json'''\n",
    "    info_dict = {}\n",
    "    # extracting the data from json file\n",
    "    info_dict['geometry'] = label_json['geometry']['coordinates']\n",
    "    info_dict['label'] = label_json['properties']['FLOODING']\n",
    "    info_dict['date'] = label_json['properties']['date']\n",
    "    info_dict['tile_number'] = label_json['properties']['tile']\n",
    "#     info_dict['full_data_coverage']= label_json['properties']['FULL-DATA-COVERAGE']\n",
    "    \n",
    "    return info_dict\n",
    "\n",
    "\n",
    "def process_label_stac(stac_json):\n",
    "    return stac_json['id']\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def image_path_from_label_dir(image_parent_dir:str,\n",
    "                              label_file :str)->str:\n",
    "    \n",
    "    return image_parent_dir + '/' + label_file.replace('labels','source')\n",
    "    \n",
    "    \n",
    "\n",
    "def process_json(label_path,image_directory):\n",
    "    '''get the data for a single example\n",
    "     Inputs \n",
    "     label_path : path to the label folder \n",
    "     image_directory: path to the corresponding image directory'''\n",
    "    \n",
    "    \n",
    "\n",
    "    #get image directory for that label\n",
    "    folder_id = label_path.rsplit('/',1)[1]\n",
    "    image_dir_path = image_path_from_label_dir(image_directory,folder_id)\n",
    "\n",
    "    if not os.path.exists(image_dir_path):\n",
    "        return {'File_not_found':image_dir_path}\n",
    "    \n",
    "    \n",
    "    for file in os.listdir(label_path):\n",
    "        #if image dir exists \n",
    "        if file.startswith('labels'):\n",
    "            label_json = load_json(os.path.join(label_path,file))\n",
    "        else:\n",
    "            stac_json = load_json(os.path.join(label_path,file))\n",
    "\n",
    "\n",
    "    #get data \n",
    "    info_dict = process_label_json(label_json)\n",
    "\n",
    "    #get id \n",
    "    info_dict['id'] = process_label_stac(stac_json)\n",
    "    \n",
    "    #location id \n",
    "    info_dict['location_id'] = info_dict['id'].split('_')[3]\n",
    "    \n",
    "    \n",
    "    info_dict['image_dir'] = image_dir_path\n",
    "    \n",
    "    \n",
    "    return info_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe(label_directory,image_directory):\n",
    "    '''get dataframe from the nested label directory'''\n",
    "    records = []\n",
    "    \n",
    "        \n",
    "    for folder in os.listdir(label_directory):\n",
    "        if folder.startswith('sen12'):\n",
    "#             print(folder,label_directory)\n",
    "            folder_path = label_directory + '/' + folder\n",
    "            \n",
    "            \n",
    "            #get data for a single example\n",
    "            feature = process_json(label_path=folder_path,\n",
    "                                   image_directory=image_directory)\n",
    "            \n",
    "            \n",
    "            records.append(feature)\n",
    "            \n",
    "            \n",
    "    return pd.DataFrame.from_records(data = records)\n",
    "\n",
    "\n",
    "\n",
    "def type_cast_dataset(dataset):\n",
    "    '''typecasting columns in dataset'''\n",
    "    dataset['label'] = dataset['label'].astype(int)\n",
    "    \n",
    "    dataset['date'] = pd.to_datetime(dataset['date'])\n",
    "    dataset['tile_number'] = dataset['tile_number'].astype('int8')\n",
    "    \n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique locations in Sentinel1 (SAR) data : 335\n",
      "Number of unique locations in Sentinel2 (optical) data : 335\n",
      "CPU times: total: 1.38 s\n",
      "Wall time: 1min 27s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((3331, 7), (2236, 7))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "s1_data = type_cast_dataset(\n",
    "                            get_dataframe(\n",
    "                                label_directory=s1_labels,\n",
    "                                image_directory=s1_tiles\n",
    "                                        )\n",
    "                            )\n",
    "\n",
    "\n",
    "s2_data = type_cast_dataset(\n",
    "                            get_dataframe(label_directory=s2_labels,\n",
    "                                          image_directory=s2_tiles)\n",
    "                            )\n",
    "\n",
    "print(f'Number of unique locations in Sentinel1 (SAR) data : {s1_data.location_id.nunique()}')\n",
    "print(f'Number of unique locations in Sentinel2 (optical) data : {s2_data.location_id.nunique()}')\n",
    "\n",
    "s1_data.shape,s2_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    " # saving datasets\n",
    "s1_data.to_csv('s1_data.csv',index=False)\n",
    "s2_data.to_csv('s2_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
